#!/usr/bin/python
'''
Utility to push this Arch hosts package and AUR caches to other host[s]
to avoid those other hosts having to download the same new package lists
and updated packages, at least for common packages. Requires root ssh
access to other hosts (it is easier with a auth key). Requires pacaur to
be installed on this host and other hosts.
'''
# Author: Mark Blakeney, Mar 2017.

import sys, os, platform, subprocess, argparse, tempfile, pickle
from pathlib import Path

# Process command line options
opt = argparse.ArgumentParser(description=__doc__)
opt.add_argument('-n', '--dryrun', action='store_true', help='dry run only')
opt.add_argument('-m', '--no-machcheck', action='store_true',
        help='do not check machine type compatibility')
opt.add_argument('-s', '--series', action='store_true',
        help='Run remote host updates in series not parallel')
opt.add_argument('hosts', nargs='+', help='hosts to update')
args = opt.parse_args()

# Save ordinary user environment to reference for later running as root
fp = tempfile.NamedTemporaryFile()
pickle.dump(dict(os.environ), fp)
fp.flush()
userenv_fname = fp.name

# If not invoked as root then re-invoke ourself using sudo
if os.geteuid() != 0:
    # Pass ssh auth so that root uses sudo user's ssh cached key
    cmd = ['/usr/bin/sudo']
    ssh_auth_sock = os.getenv('SSH_AUTH_SOCK')
    if ssh_auth_sock:
        cmd.append(f'SSH_AUTH_SOCK={ssh_auth_sock}')

    sys.exit(subprocess.run(cmd + sys.argv).returncode)

SUDO_USER = os.getenv('SUDO_USER')
if not SUDO_USER:
    sys.exit('Do not run as root. Run directly as your normal user.')

# Load calling user's environment for reference
with open(userenv_fname, 'rb') as fp:
    userenv = pickle.load(fp)

# Define paths of interest to this program
aurdest = userenv.get('AURDEST')
AURPKGS = Path(aurdest) if aurdest else \
        Path(f'~{SUDO_USER}/.cache/pacaur').expanduser()
PACLIST = Path('/var/lib/pacman/sync')
PACPKGS = Path('/var/cache/pacman/pkg')

HOST = platform.node()
MACH = platform.machine()
dryrun = '-n ' if args.dryrun else ''

def synchost(host):
    'Process given host'
    if not args.no_machcheck:
        res = subprocess.run(f'/usr/bin/ssh {host} uname -m'.split(),
                universal_newlines=True, stdout=subprocess.PIPE)

        if res.returncode != 0:
            print(f'{HOST} failed to ssh to {host}.', file=sys.stderr)
            print(f'Have you set up root ssh access to {host}?',
                    file=sys.stderr)
            return

        hostmach = res.stdout.strip()
        if hostmach != MACH:
            print(f'This {HOST} type={MACH} does not match '
                    f'{host} type={hostmach}.', file=sys.stderr)
            return

    # Push the current package lists to the host then work out what
    # package updates are required by this host. Then push all new
    # packages it requires that we already hold, including AUR files for
    # pacaur.
    print(f'{HOST} syncing {MACH} package lists to {host} ..')
    res = subprocess.run(
            f'/usr/bin/rsync -aRO --info=name1 {dryrun}'
            f'{PACLIST} {host}:/'.split())

    if res.returncode != 0:
        print(f'{HOST} failed to sync package lists to {host}.',
                file=sys.stderr)
        return

    print(f'Getting list of required package updates from {host} ..')
    res = subprocess.run(
            f'/usr/bin/ssh {host} pacaur -Qu --color=never'.split(),
            universal_newlines=True, stdout=subprocess.PIPE)

    filelist = []
    pkg = None
    for line in res.stdout.strip().splitlines():
        junk, group, name, oldver, junk, *newvers = line.split()
        newver = newvers[0]
        pkg = f'{name}-{newver}'

        # f'{host} requires update of {name} from {oldver} to {newver}'
        if group == 'aur':
            # Sync the entire build dir for an AUR package
            tpath = AURPKGS.joinpath(name)
            desc = f'AUR {name}/'
        else:
            # Can't be sure of the file (package) extension so get the
            # latest file by time.
            tpath = max(PACPKGS.glob(f'{pkg}-*'),
                    key=lambda p: p.stat().st_mtime, default=None)
            desc = pkg

        if tpath and tpath.exists():
            print(f'> {HOST} has {desc} for {host}')
            filelist.append(tpath)
        else:
            print(f'> {HOST} does not have {desc} for {host}')

    if filelist:
        print(f'{HOST} syncing updated packages to {host} ..')
        with tempfile.NamedTemporaryFile() as fp:
            fp.writelines(bytes(l) + b'\n' for l in filelist)
            fp.flush()
            subprocess.run(
                f'/usr/bin/rsync -arRO --info=name1 {dryrun}'
                f'--files-from {fp.name} / {host}:/'.split())
    elif pkg:
        print(f'{HOST} does not have any packages {host} requires.')
    else:
        print(f'{host} is already up to date.')

# May as well do in same process if only a single remote host
do_in_series = args.series or len(args.hosts) == 1

# For each host specified on the command line ..
for host in args.hosts:
    if do_in_series:
        synchost(host)
    else:
        # Do in parallel ..
        from multiprocessing import Process
        p = Process(target=synchost, args=(host,))
        p.start()
